# Polarized Words

https://defenderofbasic.github.io/good-and-evil-concepts/

100% browser based semantic embeddings demo. Computes the embedding of the input words and shows their relative distance to the pole words ("good" and "evil"). 

Here is Obama, Trump, Hitler, Kittens. Hitler is "evil" as expected. Trump is more "evil" than Obama, but both of them are way better than Hitler. Kittens is not as "good" as Obama. 

<img src="https://github.com/user-attachments/assets/1812db4f-0061-4f5a-a304-65bc44048fb2" width=400></img>

### What do these distances mean?

Concretely, these are word associations based on the training data of this language model. If the word "trump" appears with negative words a lot in newspapers, social media, etc, it will be closer to those words. 

**What it effectively tells us is how our culture talks about these ideas**. It will reflect whatever biases or connections are in the training data. It's a way to poke inside the mind of a language model, and thus, the collective consciousness of society. 

If we try polarizing words like "capitalism" and "communism", you'll get "communism" being slightly closer to "good" than capitalism. What this tells us is that, _in aggregate_, there's more net positive discourse around communism, and perhaps more talk of the evils of capitalism. 

<img src="https://github.com/user-attachments/assets/49008494-2af3-4d9d-b125-e172a7ed0f7b" width=400></img>

But society is not a monolith. **The aggregate view doesn't let us discern** between (1) everyone feels this specific way or (2) different tribes vehemently disagree. If we were to ask people to rate these words, we might see a bimodal distribution where many put "capitalism" as very good and communism as very evil, and others the reverse. 

We can validate our findings by surveying people, and by searching for corrborating evidence in the embedding relationships. We can confirm that "capitalism" leans more right wing, and "communism" leans more left wing. And to sanity check, "Obama" and "trucks" fall in the positions we expect along this line:

<img src="https://github.com/user-attachments/assets/6bbabde4-eab0-4f5e-8511-dbbaa8f64297" width=400></img>


### How the code works

All of the code is in `index.html`, there is no build system, it's just a hand written HTML/JS (initial UI was generated by Claude and I added in the semantic embedding parts). 

Below is the minimal complete vanilla JS snippet you need to (1) fetch an embedding model (2) take an arbitrary piece of text & convert it to an embedding vector.

```javascript
import { pipeline, env } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.6.0';
env.allowLocalModels = false;
// Can pick any model from here:
//  https://huggingface.co/models?other=feature-extraction
const model_name = 'nomic-ai/nomic-embed-text-v1.5'

const embedder = await pipeline('feature-extraction', model_name,
{
    quantized: true,
    progress_callback: data => {
        const { progress, loaded, total } = data
        if (progress) {
            const totalMB = Math.round(total / (1024 * 1024))
            const loadedMB = Math.round(loaded / (1024 * 1024))
            
            console.log(`${Math.round(progress)}% (${loadedMB}/${totalMB} mb)`);
        }
    }
});

const inputText = 'Hello world!'
const embeddingVector = (await embedder(inputText, {pooling: 'mean', normalize: true})).data
```

From there you can do cosine similarity between two vectors to get the distance between them, or project the words into 2D to see their relationship in concept space.

This is what it would look like for example if you got the semantic vectors for all emojis and plotted them. You can see their relationships, and the "semantic gaps":

<img src="https://github.com/user-attachments/assets/ca323507-62dd-4f51-b278-f19daf7491c1" width=400></img>

This is the same exact process that Kat (`@poetengineer__`) did here to visualize the latent space of colors. In other words, this is how an LLM "sees" color. It makes sense that similar colors cluster together.

<img src="https://github.com/user-attachments/assets/c0813c87-3c0a-4689-8cfd-9141a8820162" width=400></img>

The ðŸ¤¯ part is how every single word or phrase fits _somewhere_ in this space. 


